{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFID and PageRank Application on MIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack, lil_matrix, csr_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title Entities</th>\n",
       "      <th>Abstract Entities</th>\n",
       "      <th>TitleClust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50588</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10711</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57598</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48364</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AACk2N6.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"National Basketball Association\", ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31473</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>They seem harmless, but there's a very good re...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAAKEkt.html</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsID   Category      SubCategory   \n",
       "0   50588  lifestyle  lifestyleroyals  \\\n",
       "1   10711     health       weightloss   \n",
       "2   57598       news        newsworld   \n",
       "3   48364     health           voices   \n",
       "4   31473     health          medical   \n",
       "\n",
       "                                               Title   \n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...  \\\n",
       "1                      50 Worst Habits For Belly Fat   \n",
       "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "4  How to Get Rid of Skin Tags, According to a De...   \n",
       "\n",
       "                                            Abstract   \n",
       "0  Shop the notebooks, jackets, and more that the...  \\\n",
       "1  These seemingly harmless habits are holding yo...   \n",
       "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "3  I felt like I was a fraud, and being an NBA wi...   \n",
       "4  They seem harmless, but there's a very good re...   \n",
       "\n",
       "                                             URL   \n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html  \\\n",
       "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
       "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
       "\n",
       "                                      Title Entities   \n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...  \\\n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
       "\n",
       "                                   Abstract Entities  TitleClust  \n",
       "0                                                 []           3  \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...           7  \n",
       "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...          15  \n",
       "3  [{\"Label\": \"National Basketball Association\", ...          14  \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('MIND_Dataset/MINDprocessed/news_encoded.csv')\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_pdist(X, Y):\n",
    "    \"\"\"\n",
    "    help from https://stackoverflow.com/a/43493487\n",
    "    X: scipy.sparse CSR matrix, shape (m1, n)\n",
    "    Y: scipy.sparse CSR matrix, shape (m2, n)\n",
    "    returns: pairwise cosine distance between X and Y, shape (m1, m2)\n",
    "    \"\"\"\n",
    "    sumyy = np.asarray((Y.power(2)).sum(1)).flatten()\n",
    "    sumxx = np.asarray((X.power(2)).sum(1))\n",
    "    sumxy = X.dot(Y.T).toarray()\n",
    "    return (sumxy/np.sqrt(sumxx))/np.sqrt(sumyy)\n",
    "\n",
    "def compute_sim_matrix(combined_vectors,pb=False):\n",
    "    M = combined_vectors.shape[0]\n",
    "\n",
    "    sim_matrix = lil_matrix((M, M))\n",
    "    if pb:\n",
    "        for i in tqdm(range(M), desc=\"Processing rows\"):\n",
    "            s = cos_pdist(combined_vectors[i], combined_vectors[i:])\n",
    "            vect = np.nan_to_num(s[0].tolist(), nan=0)\n",
    "            row_i = sim_matrix[i, :]\n",
    "            filled_vect = np.concatenate((np.zeros(i, dtype=row_i.dtype), vect))\n",
    "            sim_matrix[i, :] = filled_vect\n",
    "    else:\n",
    "        for i in range(M):\n",
    "            s = cos_pdist(combined_vectors[i], combined_vectors[i:])\n",
    "            vect = np.nan_to_num(s[0].tolist(), nan=0)\n",
    "            row_i = sim_matrix[i, :]\n",
    "            filled_vect = np.concatenate((np.zeros(i, dtype=row_i.dtype), vect))\n",
    "            sim_matrix[i, :] = filled_vect\n",
    "    return sim_matrix\n",
    "\n",
    "class TfidfRecommender:\n",
    "    def __init__(self):\n",
    "        self.vectorizer1 = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "        self.vectorizer2 = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "        self.cosine_sim_matrix = None\n",
    "        self.data = None\n",
    "        self.title_vectors = None\n",
    "        self.attr_vectors = None\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.data = data.copy()\n",
    "        #name = data.columns[0]\n",
    "        attribute1 = data.columns[1]\n",
    "        attribute2 = data.columns[2]\n",
    "        \n",
    "        self.title_vectors = self.vectorizer1.fit_transform(data[attribute1])\n",
    "        self.attr_vectors = self.vectorizer2.fit_transform(data[attribute2])\n",
    "        # Combine vectors\n",
    "        combined_vectors = hstack((self.title_vectors, self.attr_vectors))\n",
    "        \n",
    "        # Compute cosine similarity matrix\n",
    "        self.cosine_sim_matrix = compute_sim_matrix(combined_vectors)\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "    def recommend(self, attr1=[], attr2=[], top_n=5):\n",
    "        if not self.fitted:\n",
    "            raise(\"Error, recommender not fitted\")\n",
    "        else:\n",
    "            name = self.data.columns[0]\n",
    "            attribute1 = self.data.columns[1]\n",
    "            attribute2 = self.data.columns[2]\n",
    "            \n",
    "            # Filter movies based on specified attr1\n",
    "            if len(attr1)>0:\n",
    "                attr1_items = self.data[self.data[attribute1].apply(lambda x: any(item in attr1 for item in x) if isinstance(x, list) else x in attr1)]\n",
    "            else:\n",
    "                attr1_items = self.data\n",
    "\n",
    "            # Filter movies based on specified attr2\n",
    "            if len(attr2)>0:\n",
    "                attr2_items = self.data[self.data[attribute2].apply(lambda x: any(item in attr2 for item in x) if isinstance(x, list) else x in attr2)]\n",
    "            else:\n",
    "                attr2_items = self.data\n",
    "\n",
    "            # Get intersection of movies based on genres and actors\n",
    "            selected_movies = attr1_items[attr1_items.index.isin(attr2_items.index)]\n",
    "            #size = sys.getsizeof(selected_movies)\n",
    "            \n",
    "            if selected_movies.empty:\n",
    "                return \"No items found for the given attributes.\"\n",
    "\n",
    "            # Get the index of the selected movies in the movie data\n",
    "            selected_indices = selected_movies.index\n",
    "\n",
    "            # Compute the average cosine similarity for each selected movie\n",
    "            avg_similarity = self.cosine_sim_matrix[selected_indices].mean(axis=0)\n",
    "\n",
    "            # Sort movies based on average similarity in descending order\n",
    "            sorted_indices = np.argsort(avg_similarity.tolist()[0])[::-1].tolist()\n",
    "\n",
    "            # Get the top N recommended movie indices\n",
    "            top_indices = sorted_indices[:top_n]\n",
    "\n",
    "            # Get the top N recommended movie titles\n",
    "            recommended_movies = self.data.iloc[top_indices,:][name]\n",
    "\n",
    "            return recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample movie data\n",
    "movie_data = pd.DataFrame({\n",
    "    'Title': ['Movie A', 'Movie B', 'Movie C', 'Movie D'],\n",
    "    'Genres': [['Action', 'Thriller'], ['Action','Drama','Romance'], ['Comedy'], ['Action', 'Comedy']],\n",
    "    'Actors': [['Actor1', 'Actor2'], ['Actor3', 'Actor4'], ['Actor2'], ['Actor1', 'Actor4']]\n",
    "})\n",
    "\n",
    "# Create an instance of the TfidfRecommender class\n",
    "recommender = TfidfRecommender()\n",
    "\n",
    "# Fit the recommender with the movie data\n",
    "recommender.fit(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    Movie D\n",
      "1    Movie B\n",
      "2    Movie C\n",
      "Name: Title, dtype: object\n",
      "##########################\n",
      "3    Movie D\n",
      "1    Movie B\n",
      "0    Movie A\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Make recommendations for a specific genre\n",
    "recommended_movies = recommender.recommend(attr2=['Actor4'], top_n=3)\n",
    "print(recommended_movies)\n",
    "\n",
    "print(\"##########################\")\n",
    "# Make recommendations for a specific genre\n",
    "recommended_movies = recommender.recommend(attr1=['Action','Drama'], top_n=3)\n",
    "print(recommended_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "news             12324\n",
       "sports           10715\n",
       "finance           2548\n",
       "foodanddrink      2137\n",
       "lifestyle         2068\n",
       "travel            1794\n",
       "health            1623\n",
       "video             1511\n",
       "weather           1496\n",
       "autos             1369\n",
       "tv                 766\n",
       "music              608\n",
       "movies             524\n",
       "entertainment      503\n",
       "kids                12\n",
       "middleeast           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_reduced = news.head(40000)\n",
    "news_reduced.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the TfidfRecommender class\n",
    "recommender = TfidfRecommender()\n",
    "\n",
    "# Fit the recommender with the movie data\n",
    "recommender.fit(news_reduced[['Title','Category','SubCategory']])\n",
    "\n",
    "# Make recommendations for a specific genre\n",
    "recommended_movies = recommender.recommend(attr1=['sports'], top_n=10)\n",
    "print(recommended_movies)\n",
    "\n",
    "print(\"##########################\")\n",
    "# Make recommendations for a specific genre\n",
    "recommended_movies = recommender.recommend(attr1=['kids'], top_n=10)\n",
    "print(recommended_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "for _, row in news.iterrows():\n",
    "    source = row['NewsID']\n",
    "    target1 = row['Category']\n",
    "    target2 = row['SubCategory']\n",
    "    relation1 = 'Has category'\n",
    "    relation2 = 'Has subcategory'\n",
    "    G.add_node(source)\n",
    "    G.add_node(target1)\n",
    "    G.add_node(target2)\n",
    "    G.add_edge(source, target1, relation=relation1)\n",
    "    G.add_edge(source, target2, relation=relation2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "#pos = nx.spring_layout(G)\n",
    "#nx.draw_networkx_nodes(G, pos, node_color='lightblue')\n",
    "#nx.draw_networkx_edges(G, pos, edge_color='gray')\n",
    "#nx.draw_networkx_labels(G, pos)\n",
    "#nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(graph, 'relation'))\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PageRank scores with edge weights\n",
    "pagerank_scores = nx.pagerank(G, weight='weight')\n",
    "\n",
    "# Sort the nodes by PageRank score in descending order\n",
    "sorted_nodes = sorted(pagerank_scores, key=pagerank_scores.get, reverse=True)\n",
    "\n",
    "for id in news.NewsID:\n",
    "    sorted_nodes.remove(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news 0.07889004511242838\n",
      "sports 0.07025342294647274\n",
      "newsus 0.03204629339752906\n",
      "football_nfl 0.027057158176892776\n",
      "finance 0.013806644622683455\n",
      "newspolitics 0.01261043291687287\n",
      "lifestyle 0.011490493211613526\n",
      "foodanddrink 0.011365739885240325\n",
      "travel 0.010952166838212757\n",
      "video 0.01024599373031153\n"
     ]
    }
   ],
   "source": [
    "# Print the ranking\n",
    "for node in sorted_nodes[:10]:\n",
    "    print(node, pagerank_scores[node])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies in the Action genre:\n",
      "3    Movie D\n",
      "2    Movie C\n",
      "1    Movie B\n",
      "0    Movie A\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Sample movie data\n",
    "movie_data = pd.DataFrame({\n",
    "    'Title': ['Movie A', 'Movie B', 'Movie C', 'Movie D'],\n",
    "    'Genres': [['Action', 'Thriller'], ['Drama', 'Romance'], ['Comedy'], ['Action', 'Comedy']]\n",
    "})\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "\n",
    "# Fit and transform the movie titles\n",
    "title_vectors = vectorizer.fit_transform(movie_data['Title'])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(title_vectors)\n",
    "\n",
    "def recommend_movies_by_genre(genre, movie_data, cosine_sim_matrix, top_n=5):\n",
    "    # Get indices of movies with the specified genre\n",
    "    genre_movies = movie_data[movie_data['Genres'].apply(lambda x: genre in x)]\n",
    "\n",
    "    if genre_movies.empty:\n",
    "        return \"No movies found for the given genre.\"\n",
    "\n",
    "    # Get the index of the genre movie in the movie data\n",
    "    genre_movie_indices = genre_movies.index\n",
    "\n",
    "    # Compute the average cosine similarity for each genre movie\n",
    "    avg_similarity = cosine_sim_matrix[genre_movie_indices].mean(axis=0)\n",
    "\n",
    "    # Sort movies based on average similarity in descending order\n",
    "    sorted_indices = avg_similarity.argsort()[::-1]\n",
    "\n",
    "    # Get the top N recommended movie indices\n",
    "    top_indices = sorted_indices[:top_n]\n",
    "\n",
    "    # Get the top N recommended movie titles\n",
    "    recommended_movies = movie_data.iloc[top_indices]['Title']\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "# Example usage\n",
    "genre = 'Action'\n",
    "recommendations = recommend_movies_by_genre(genre, movie_data, cosine_sim_matrix)\n",
    "print(f\"Recommended movies in the {genre} genre:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Sample movie data\n",
    "movie_data = pd.DataFrame({\n",
    "    'Title': ['Movie A', 'Movie B', 'Movie C', 'Movie D'],\n",
    "    'Genres': [['Action', 'Thriller'], ['Drama', 'Romance'], ['Comedy'], ['Action', 'Comedy']],\n",
    "    'Actors': [['Actor1', 'Actor2'], ['Actor3', 'Actor4'], ['Actor2'], ['Actor1', 'Actor4']]\n",
    "})\n",
    "\n",
    "# Create TF-IDF vectorizer for movie titles\n",
    "title_vectorizer = TfidfVectorizer(lowercase=False)\n",
    "title_vectors = title_vectorizer.fit_transform(movie_data['Title'])\n",
    "\n",
    "# Create TF-IDF vectorizer for movie actors\n",
    "actor_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "actor_vectors = actor_vectorizer.fit_transform(movie_data['Actors'])\n",
    "\n",
    "# Combine title and actor vectors\n",
    "combined_vectors = hstack((title_vectors, actor_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Sample movie data\n",
    "movie_data = pd.DataFrame({\n",
    "    'Title': ['Movie A', 'Movie B', 'Movie C', 'Movie D'],\n",
    "    'Genres': [['Action', 'Thriller'], ['Drama', 'Romance'], ['Comedy'], ['Action', 'Comedy']],\n",
    "    'Actors': [['Actor1', 'Actor2'], ['Actor3', 'Actor4'], ['Actor2'], ['Actor1', 'Actor4']]\n",
    "})\n",
    "\n",
    "# Create TF-IDF vectorizer for movie titles\n",
    "title_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "title_vectors = title_vectorizer.fit_transform(movie_data['Title'])\n",
    "\n",
    "# Create TF-IDF vectorizer for movie actors\n",
    "actor_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "actor_vectors = actor_vectorizer.fit_transform(movie_data['Actors'])\n",
    "\n",
    "# Combine title and actor vectors\n",
    "combined_vectors = hstack((title_vectors, actor_vectors))\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(combined_vectors)\n",
    "\n",
    "def recommend_movies(genres, actors, movie_data, cosine_sim_matrix, top_n=5):\n",
    "    # Filter movies based on specified genres\n",
    "    if genres:\n",
    "        genre_movies = movie_data[movie_data['Genres'].apply(lambda x: any(genre in x for genre in genres))]\n",
    "    else:\n",
    "        genre_movies = movie_data\n",
    "\n",
    "    # Filter movies based on specified actors\n",
    "    if actors:\n",
    "        actor_movies = movie_data[movie_data['Actors'].apply(lambda x: any(actor in x for actor in actors))]\n",
    "    else:\n",
    "        actor_movies = movie_data\n",
    "\n",
    "    # Get intersection of movies based on genres and actors\n",
    "    selected_movies = genre_movies[genre_movies.index.isin(actor_movies.index)]\n",
    "\n",
    "    if selected_movies.empty:\n",
    "        return \"No movies found for the given genres and actors.\"\n",
    "\n",
    "    # Get the index of the selected movies in the movie data\n",
    "    selected_indices = selected_movies.index\n",
    "\n",
    "    # Compute the average cosine similarity for each selected movie\n",
    "    avg_similarity = cosine_sim_matrix[selected_indices].mean(axis=0)\n",
    "\n",
    "    # Sort movies based on average similarity in descending order\n",
    "    sorted_indices = avg_similarity.argsort()[::-1]\n",
    "\n",
    "    # Get the top N recommended movie indices\n",
    "    top_indices = sorted_indices[:top_n]\n",
    "\n",
    "    # Get the top N recommended movie titles\n",
    "    recommended_movies = movie_data.iloc[top_indices]['Title']\n",
    "\n",
    "    return recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies based on genres and actors:\n",
      "3    Movie D\n",
      "0    Movie A\n",
      "2    Movie C\n",
      "1    Movie B\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "genres = ['Action', 'Thriller']\n",
    "actors = ['Actor1', 'Actor2']\n",
    "recommendations = recommend_movies(genres, actors, movie_data, cosine_sim_matrix)\n",
    "print(\"Recommended movies based on genres and actors:\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies based on genres:\n",
      "1    Movie B\n",
      "3    Movie D\n",
      "2    Movie C\n",
      "0    Movie A\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "genres = ['Drama']\n",
    "recommendations = recommend_movies(genres, actors=None, movie_data=movie_data, cosine_sim_matrix=cosine_sim_matrix)\n",
    "print(\"Recommended movies based on genres:\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Movie A</td>\n",
       "      <td>[Action, Thriller]</td>\n",
       "      <td>[Actor1, Actor2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie B</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>[Actor3, Actor4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movie C</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>[Actor2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Movie D</td>\n",
       "      <td>[Action, Comedy]</td>\n",
       "      <td>[Actor1, Actor4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Title              Genres            Actors\n",
       "0  Movie A  [Action, Thriller]  [Actor1, Actor2]\n",
       "1  Movie B    [Drama, Romance]  [Actor3, Actor4]\n",
       "2  Movie C            [Comedy]          [Actor2]\n",
       "3  Movie D    [Action, Comedy]  [Actor1, Actor4]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "class TfidfRecommender:\n",
    "    def __init__(self):\n",
    "        self.vectorizer1 = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "        self.vectorizer2 = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "        self.cosine_sim_matrix = None\n",
    "        self.data = None\n",
    "        self.title_vectors = None\n",
    "        self.attr_vectors = None\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.data = data.copy()\n",
    "        name = data.columns[0]\n",
    "        #attribute1 = data.columns[1]\n",
    "        attribute2 = data.columns[2]\n",
    "        \n",
    "        self.title_vectors = self.vectorizer1.fit_transform(data[name])\n",
    "        self.attr_vectors = self.vectorizer2.fit_transform(data[attribute2])\n",
    "        # Combine vectors\n",
    "        combined_vectors = hstack((self.title_vectors, self.attr_vectors))\n",
    "        # Compute cosine similarity matrix\n",
    "        self.cosine_sim_matrix = cosine_similarity(combined_vectors)\n",
    "        \n",
    "        self.fitted = True\n",
    "\n",
    "    def recommend(self, attr1=None, attr2=None, top_n=5):\n",
    "        if not self.fitted:\n",
    "            raise(\"Error, recommender not fitted\")\n",
    "        else:\n",
    "            name = self.data.columns[0]\n",
    "            attribute1 = self.data.columns[1]\n",
    "            attribute2 = self.data.columns[2]\n",
    "            \n",
    "            # Filter movies based on specified attr1\n",
    "            if attr1:\n",
    "                attr1_items = movie_data[movie_data[attribute1].apply(lambda x: attr1 in x)]\n",
    "            else:\n",
    "                attr1_items = self.data\n",
    "\n",
    "            # Filter movies based on specified attr2\n",
    "            if attr2:\n",
    "                attr2_items = movie_data[movie_data[attribute2].apply(lambda x: attr2 in x)]\n",
    "            else:\n",
    "                attr2_items = self.data\n",
    "\n",
    "            # Get intersection of movies based on genres and actors\n",
    "            selected_movies = attr1_items[attr1_items.index.isin(attr2_items.index)]\n",
    "\n",
    "            if selected_movies.empty:\n",
    "                return \"No items found for the given attributes.\"\n",
    "\n",
    "            # Get the index of the selected movies in the movie data\n",
    "            selected_indices = selected_movies.index\n",
    "\n",
    "            # Compute the average cosine similarity for each selected movie\n",
    "            avg_similarity = self.cosine_sim_matrix[selected_indices].mean(axis=0)\n",
    "\n",
    "            # Sort movies based on average similarity in descending order\n",
    "            sorted_indices = avg_similarity.argsort()[::-1]\n",
    "\n",
    "            # Get the top N recommended movie indices\n",
    "            top_indices = sorted_indices[:top_n]\n",
    "\n",
    "            # Get the top N recommended movie titles\n",
    "            recommended_movies = self.data.iloc[top_indices][name]\n",
    "\n",
    "            return recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    Movie D\n",
      "1    Movie B\n",
      "0    Movie A\n",
      "Name: Title, dtype: object\n",
      "##########################\n",
      "1    Movie B\n",
      "3    Movie D\n",
      "2    Movie C\n",
      "Name: Title, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample movie data\n",
    "movie_data = pd.DataFrame({\n",
    "    'Title': ['Movie A', 'Movie B', 'Movie C', 'Movie D'],\n",
    "    'Genres': [['Action', 'Thriller'], ['Drama', 'Romance'], ['Comedy'], ['Action', 'Comedy']],\n",
    "    'Actors': [['Actor1', 'Actor2'], ['Actor3', 'Actor4'], ['Actor2'], ['Actor1', 'Actor4']]\n",
    "})\n",
    "\n",
    "# Create an instance of the TfidfRecommender class\n",
    "recommender = TfidfRecommender()\n",
    "\n",
    "# Fit the recommender with the movie data\n",
    "recommender.fit(movie_data)\n",
    "\n",
    "# Make recommendations for a specific genre\n",
    "recommended_movies = recommender.recommend(attr2='Actor4', top_n=3)\n",
    "print(recommended_movies)\n",
    "\n",
    "print(\"##########################\")\n",
    "# Make recommendations for a specific genre\n",
    "recommended_movies = recommender.recommend(attr1='Drama', top_n=3)\n",
    "print(recommended_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Title            Genres            Actors\n",
      "1  Movie B  [Drama, Romance]  [Actor3, Actor4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample movie data\n",
    "movie_data = pd.DataFrame({\n",
    "    'Title': ['Movie A', 'Movie B', 'Movie C', 'Movie D'],\n",
    "    'Genres': [['Action', 'Thriller'], ['Drama', 'Romance'], ['Comedy'], ['Action', 'Comedy']],\n",
    "    'Actors': [['Actor1', 'Actor2'], ['Actor3', 'Actor4'], ['Actor2'], ['Actor1', 'Actor4']]\n",
    "})\n",
    "\n",
    "attribute1 = movie_data.columns[1]\n",
    "attr1 = 'Drama'\n",
    "attr1_items = movie_data[movie_data[attribute1].apply(lambda x: attr1 in x)]\n",
    "\n",
    "print(attr1_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "Name: Genres, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute1 = 'genres'\n",
    "movie_data[attribute1].apply(lambda x: any(a in x for a in attr1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre 1 0.37012974744707666\n",
      "Actor 1 0.37012974744707666\n",
      "Movie A 0.25974050510584634\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_node('Movie A')\n",
    "graph.add_node('Genre 1')\n",
    "graph.add_node('Actor 1')\n",
    "\n",
    "# Add labeled edges to the graph\n",
    "graph.add_edge('Movie A', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie A', 'Actor 1', label='has_actor')\n",
    "\n",
    "# Calculate PageRank scores with edge weights\n",
    "pagerank_scores = nx.pagerank(graph, weight='weight')\n",
    "\n",
    "# Sort the nodes by PageRank score in descending order\n",
    "sorted_nodes = sorted(pagerank_scores, key=pagerank_scores.get, reverse=True)\n",
    "\n",
    "# Print the ranking\n",
    "for node in sorted_nodes:\n",
    "    print(node, pagerank_scores[node])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre 1 0.23584829392560236\n",
      "Actor 1 0.17169774276386401\n",
      "Actor 2 0.1396224671829948\n",
      "Movie A 0.07547191602125641\n",
      "Movie B 0.07547191602125641\n",
      "Movie C 0.07547191602125641\n",
      "Movie D 0.07547191602125641\n",
      "Movie E 0.07547191602125641\n",
      "Genre 2 0.07547191602125641\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_node('Movie A')\n",
    "graph.add_node('Movie B')\n",
    "graph.add_node('Movie C')\n",
    "graph.add_node('Movie D')\n",
    "graph.add_node('Movie E')\n",
    "graph.add_node('Genre 1')\n",
    "graph.add_node('Genre 2')\n",
    "graph.add_node('Actor 1')\n",
    "graph.add_node('Actor 2')\n",
    "\n",
    "# Add labeled edges to the graph\n",
    "graph.add_edge('Movie A', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie A', 'Actor 1', label='has_actor')\n",
    "graph.add_edge('Movie B', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie B', 'Actor 2', label='has_actor')\n",
    "graph.add_edge('Movie C', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie C', 'Actor 1', label='has_actor')\n",
    "graph.add_edge('Movie D', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie D', 'Actor 2', label='has_actor')\n",
    "graph.add_edge('Movie E', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie E', 'Actor 1', label='has_actor')\n",
    "\n",
    "# Calculate PageRank scores with edge weights\n",
    "pagerank_scores = nx.pagerank(graph, weight='weight')\n",
    "\n",
    "# Sort the nodes by PageRank score in descending order\n",
    "sorted_nodes = sorted(pagerank_scores, key=pagerank_scores.get, reverse=True)\n",
    "\n",
    "# Print the ranking\n",
    "for node in sorted_nodes:\n",
    "    print(node, pagerank_scores[node])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre 1 0.20377301834473324\n",
      "Actor 1 0.17169774276386401\n",
      "Actor 2 0.1396224671829948\n",
      "Genre 2 0.10754719160212561\n",
      "Movie A 0.07547191602125641\n",
      "Movie B 0.07547191602125641\n",
      "Movie C 0.07547191602125641\n",
      "Movie D 0.07547191602125641\n",
      "Movie E 0.07547191602125641\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_node('Movie A')\n",
    "graph.add_node('Movie B')\n",
    "graph.add_node('Movie C')\n",
    "graph.add_node('Movie D')\n",
    "graph.add_node('Movie E')\n",
    "graph.add_node('Genre 1')\n",
    "graph.add_node('Genre 2')\n",
    "graph.add_node('Actor 1')\n",
    "graph.add_node('Actor 2')\n",
    "\n",
    "# Add labeled edges to the graph\n",
    "graph.add_edge('Movie A', 'Genre 2', label='has_genre')\n",
    "graph.add_edge('Movie A', 'Actor 1', label='has_actor')\n",
    "graph.add_edge('Movie B', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie B', 'Actor 2', label='has_actor')\n",
    "graph.add_edge('Movie C', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie C', 'Actor 1', label='has_actor')\n",
    "graph.add_edge('Movie D', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie D', 'Actor 2', label='has_actor')\n",
    "graph.add_edge('Movie E', 'Genre 1', label='has_genre')\n",
    "graph.add_edge('Movie E', 'Actor 1', label='has_actor')\n",
    "\n",
    "# Calculate PageRank scores with edge weights\n",
    "pagerank_scores = nx.pagerank(graph, weight='weight')\n",
    "\n",
    "# Sort the nodes by PageRank score in descending order\n",
    "sorted_nodes = sorted(pagerank_scores, key=pagerank_scores.get, reverse=True)\n",
    "\n",
    "# Print the ranking\n",
    "for node in sorted_nodes:\n",
    "    print(node, pagerank_scores[node])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cose che potranno diventare utili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack, csr_matrix, lil_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from scipy.sparse.linalg import norm\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "# News data import\n",
    "news = pd.read_csv('Mind_Dataset/MINDprocessed/news_encoded.csv')\n",
    "news = news.head(10000)\n",
    "\n",
    "vectorizer1 = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "vectorizer2 = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "\n",
    "attribute1 = news.columns[1]\n",
    "attribute2 = news.columns[2]\n",
    "\n",
    "title_vectors = vectorizer1.fit_transform(news[attribute1])\n",
    "attr_vectors = vectorizer2.fit_transform(news[attribute2])\n",
    "\n",
    "# Combine vectors\n",
    "combined_vectors = hstack((title_vectors, attr_vectors))\n",
    "\n",
    "M = combined_vectors.shape[0]\n",
    "\n",
    "#pool = mp.Pool(mp.cpu_count())\n",
    "pool = mp.Pool(4)\n",
    "\n",
    "sim_matrix = lil_matrix((M, M))\n",
    "\n",
    "# Step 1: Redefine, to accept `i`, the iteration number\n",
    "def cos_pdist(i, X, Y):\n",
    "    \"\"\"\n",
    "    help from https://stackoverflow.com/a/43493487\n",
    "    X: scipy.sparse CSR matrix, shape (m1, n)\n",
    "    Y: scipy.sparse CSR matrix, shape (m2, n)\n",
    "    returns: pairwise cosine distance between X and Y, shape (m1, m2)\n",
    "    \"\"\"\n",
    "    sumyy = np.asarray((Y.power(2)).sum(1)).flatten()\n",
    "    sumxx = np.asarray((X.power(2)).sum(1))\n",
    "    sumxy = X.dot(Y.T).toarray()\n",
    "    result = (sumxy/np.sqrt(sumxx))/np.sqrt(sumyy)\n",
    "    return (i, result)\n",
    "\n",
    "\n",
    "# Step 2: Define callback function to collect the output in `results`\n",
    "def collect_result(i,result):\n",
    "    global sim_matrix\n",
    "    sim_matrix[i,:] = result\n",
    "\n",
    "data = combined_vectors\n",
    "\n",
    "with tqdm(total=data.shape[0]) as t:\n",
    "\n",
    "    # Step 3: Use loop to parallelize\n",
    "    for i, row in enumerate(data):\n",
    "        #print(\"Prontoooooooooooooooooooooo??\")\n",
    "        pool.apply_async(cos_pdist, args=(i, data[i], data[i:]), callback=collect_result)\n",
    "        t.update()\n",
    "    # Step 4: Close Pool and let all the processes complete  \n",
    "    print(\"Prontoooooooooooooooooooooo??\")  \n",
    "    pool.close()\n",
    "    print(\"Prontoooooooooooooooooooooo??\")\n",
    "    pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
    "    print(\"Prontoooooooooooooooooooooo??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
